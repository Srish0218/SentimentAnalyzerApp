{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:18:51.254767100Z",
     "start_time": "2023-11-19T13:18:50.607392900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57c9f8e79ec6c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:18:57.154759700Z",
     "start_time": "2023-11-19T13:18:57.129324600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spend your money elsewhere.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Their regular toasted bread was equally satisf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Buffet at Bellagio was far from what I ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the drinks are WEAK, people!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-My order was not correct.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0                        Spend your money elsewhere.\n",
       "1  Their regular toasted bread was equally satisf...\n",
       "2  The Buffet at Bellagio was far from what I ant...\n",
       "3                   And the drinks are WEAK, people!\n",
       "4                         -My order was not correct."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('a2_RestaurantReviews_FreshDump.tsv', delimiter = '\\t', quoting = 3)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b98d29bea81b5",
   "metadata": {},
   "source": [
    "Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a54422da214699d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:19:27.258199600Z",
     "start_time": "2023-11-19T13:19:25.257629Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\srish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6d01e0ff6e0fd78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:19:38.417973600Z",
     "start_time": "2023-11-19T13:19:38.382427300Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "\n",
    "for i in range(0, 100):\n",
    "  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "  review = review.lower()\n",
    "  review = review.split()\n",
    "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "  review = ' '.join(review)\n",
    "  corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d26fd94d4515e",
   "metadata": {},
   "source": [
    "Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5a0678f61a973f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:19:59.317518900Z",
     "start_time": "2023-11-19T13:19:59.286521Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srish\\PycharmProjects\\venv\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator CountVectorizer from version 1.0.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loading BoW dictionary\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "cvFile='c1_BoW_Sentiment_Model.pkl'\n",
    "# cv = CountVectorizer(decode_error=\"replace\", vocabulary=pickle.load(open('./drive/MyDrive/Colab Notebooks/2 Sentiment Analysis (Basic)/3.1 BoW_Sentiment Model.pkl', \"rb\")))\n",
    "cv = pickle.load(open(cvFile, \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fee225f4515b4a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:20:31.377527200Z",
     "start_time": "2023-11-19T13:20:31.367410600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1420)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fresh = cv.transform(corpus).toarray()\n",
    "X_fresh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d895324be8b4bc",
   "metadata": {},
   "source": [
    "Predictions (via sentiment classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6133c71dd06f0985",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:20:42.758497400Z",
     "start_time": "2023-11-19T13:20:42.725503700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srish\\PycharmProjects\\venv\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator GaussianNB from version 1.0.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "classifier = joblib.load('c2_Classifier_Sentiment_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42041aaed94f437b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:20:48.030742Z",
     "start_time": "2023-11-19T13:20:48.015092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_fresh)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0221f56ddc31f70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:20:57.427449Z",
     "start_time": "2023-11-19T13:20:57.412980600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spend your money elsewhere.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Their regular toasted bread was equally satisf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Buffet at Bellagio was far from what I ant...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the drinks are WEAK, people!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-My order was not correct.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  predicted_label\n",
       "0                        Spend your money elsewhere.                0\n",
       "1  Their regular toasted bread was equally satisf...                1\n",
       "2  The Buffet at Bellagio was far from what I ant...                1\n",
       "3                   And the drinks are WEAK, people!                0\n",
       "4                         -My order was not correct.                0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['predicted_label'] = y_pred.tolist()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831f1f3cba4d616",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-02T13:29:12.532025200Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "dataset.to_csv(\"c3_Predicted_Sentiments_Results.tsv\", sep='\\t', encoding='UTF-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b54ae45e41c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
